{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vAMjCW1ZvKfg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFbs_BZ1vJ-d",
        "outputId": "baae305d-c7fc-46df-df18-3ec8f202cd9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300.0, 572.7669683213235, 759.6459701729484)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Total RIS elements M:\n",
        "M = 256\n",
        "sigma = np.power(10,-8.5)       #-55\n",
        "num_users = 4\n",
        "# Coordinates of AP(x_ap, y_ap, z_ap):\n",
        "AP = [0, 0, 0]\n",
        "\n",
        "# Coordinates of RIS(x_r, y_r, z_r):\n",
        "RIS = [300, 0, 0]\n",
        "\n",
        "# Coordinates of user k(x_k, y_k, z_k):\n",
        "users = []\n",
        "for user in range(num_users):\n",
        "    users.append([np.random.randint(-500, 800), np.random.randint(-500,500), np.random.randint(-500,500)])\n",
        "\n",
        "def distance(p1, p2):\n",
        "    return math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2 + (p1[2]-p2[2])**2)\n",
        "\n",
        "distance(AP, RIS), distance(AP, users[0]), distance(RIS, users[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwrKkp4M6vIW",
        "outputId": "99a30611-1c43-4531-9f1b-dba1800f2a18"
      },
      "outputs": [],
      "source": [
        "# Calculating NLos vectors for v, gk:\n",
        "v_nlos = np.random.normal(0, math.sqrt(0.5), size=(M,1)) + np.random.normal(0, math.sqrt(0.5), size=(M,1))\n",
        "gk_nlos = np.random.normal(0, math.sqrt(0.5), size=(M,1)) + np.random.normal(0, math.sqrt(0.5), size=(M,1))\n",
        "rk_nlos = np.random.normal(0, math.sqrt(0.5), size=(1,1)) + np.random.normal(0, math.sqrt(0.5), size=(1,1))\n",
        "\n",
        "\n",
        "v_nlos = v_nlos.ravel().tolist()\n",
        "gk_nlos = gk_nlos.ravel().tolist()\n",
        "rk_nlos = rk_nlos.ravel().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HXzcuCfrAhSC"
      },
      "outputs": [],
      "source": [
        "# Generating v_los:\n",
        "v_los = []\n",
        "\n",
        "def sin_a_AR(x1,x2,y1,y2):\n",
        "    return (y1-y2)/math.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
        "\n",
        "for m in range(1, M+1):\n",
        "    v_los.append( math.cos((m-1)*math.pi*sin_a_AR(RIS[0], AP[0], RIS[1], AP[1])) \n",
        "              + (1j)*math.sin((m-1)*math.pi*sin_a_AR(RIS[0], AP[0], RIS[1], AP[1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OVx0ZeAvF-Cy"
      },
      "outputs": [],
      "source": [
        "# Generating gk_los:\n",
        "gk_los = [[] for _ in range(num_users)]\n",
        "\n",
        "for user in range(num_users):\n",
        "    for m in range(1, M+1):\n",
        "        gk_los[user].append( math.cos((m-1)*math.pi*sin_a_AR(users[user][0], RIS[0], users[user][1], RIS[1])) \n",
        "                         + (1j)*math.sin((m-1)*math.pi*sin_a_AR(users[user][0], RIS[0], users[user][1], RIS[1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7hsb0ZaOIozf"
      },
      "outputs": [],
      "source": [
        "# Generating v[n]:\n",
        "v = []\n",
        "rho_0 = 30       # actual rho_0 = -30 (using 1j later)\n",
        "d_0 = 1\n",
        "alpha = 3*(10**(-4))\n",
        "K_AR = 3\n",
        "K_RU = 3\n",
        "\n",
        "def PL(d):\n",
        "    # print(rho_0*((d/d_0)**alpha))\n",
        "    return rho_0*((d/d_0)**alpha)\n",
        "\n",
        "def generate_v():\n",
        "    for m in range(1, M+1):\n",
        "        v.append( 1j*math.sqrt(PL(300)) * (math.sqrt(K_AR/(K_AR+1)) *v_los[m-1] + math.sqrt(1/(K_AR+1)) *v_nlos[m-1]) )\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XTRzpnprOYbo"
      },
      "outputs": [],
      "source": [
        "# Generating g_k[n]:\n",
        "gk = [[] for _ in range(num_users)]\n",
        "\n",
        "def generate_gk():\n",
        "    for user in range(num_users):\n",
        "        for m in range(1, M+1):\n",
        "            gk[user].append( 1j*math.sqrt(PL(distance(RIS, users[user]))) * (math.sqrt(K_RU/(K_RU+1)) *gk_los[user][m-1] + math.sqrt(1/(K_RU+1)) *gk_nlos[m-1]) )\n",
        "    return gk   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7-epuyaE6mpb"
      },
      "outputs": [],
      "source": [
        "rk = [[] for _ in range(num_users)]\n",
        "\n",
        "def generate_rk():\n",
        "    for user in range(num_users):\n",
        "        rk[user].append( 1j*math.sqrt(PL(distance( AP, users[user]))) *rk_nlos[0])\n",
        "    return rk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BsUh2gvpBqbj"
      },
      "outputs": [],
      "source": [
        "# Generating theta\n",
        "def generate_theta():\n",
        "    theta = []\n",
        "    for m in range(M):\n",
        "        theta.append(np.random.uniform(0, 2*math.pi, M))\n",
        "    # theta.ravel().tolist()\n",
        "    return theta\n",
        "# theta_matrix = generate_theta()\n",
        "# theta = [theta_matrix[i][i] for i in range(len(theta_matrix))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl5OMybgPamI",
        "outputId": "d9b8f4cf-d057-45fa-b845-25c8aa1a0d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 513) (4, 257)\n",
            "                  gk0                 gk1                 gk2  \\\n",
            "0  0.000000+3.638649j -2.341041+2.054767j -4.073432-2.600551j   \n",
            "0  0.000000+3.638333j  2.908338+1.676708j  4.597573-3.855204j   \n",
            "0  0.000000+3.638292j -3.625484-5.141260j  4.681582-5.829135j   \n",
            "0  0.000000+3.638431j  4.680523-1.279258j  1.570904-9.520356j   \n",
            "\n",
            "                  gk3                 gk4                 gk5  \\\n",
            "0 -4.746766-2.141657j -4.185982+0.728405j -2.536879-4.140819j   \n",
            "0  4.359619-4.135656j  2.294221-1.187404j -0.732859-4.818021j   \n",
            "0 -2.419835+1.829127j -1.556852-1.515975j  4.430196+1.579773j   \n",
            "0 -4.153287-4.556163j -2.964854+6.677626j  3.158206+3.417914j   \n",
            "\n",
            "                  gk6                 gk7                 gk8  \\\n",
            "0 -0.228210-7.183016j  2.139792+1.927489j  3.951467+2.275781j   \n",
            "0 -3.452742-5.698906j -4.725321+5.704902j -4.017162+7.438456j   \n",
            "0 -4.163853-0.159180j  0.946581+1.513177j  2.941534+8.634554j   \n",
            "0  4.024830-4.958721j -1.807369+1.775373j -4.631429+5.953088j   \n",
            "\n",
            "                  gk9  ...                v247               v248  \\\n",
            "0  4.735795+1.934569j  ...  0.000000+4.397436j  0.00000+10.25722j   \n",
            "0 -1.625109+6.737453j  ...  0.000000+4.397436j  0.00000+10.25722j   \n",
            "0 -4.744980+2.116656j  ...  0.000000+4.397436j  0.00000+10.25722j   \n",
            "0  0.252942+7.017693j  ...  0.000000+4.397436j  0.00000+10.25722j   \n",
            "\n",
            "                 v249                v250                v251  \\\n",
            "0  0.000000+0.857786j  0.000000+4.130941j  0.000000+7.706829j   \n",
            "0  0.000000+0.857786j  0.000000+4.130941j  0.000000+7.706829j   \n",
            "0  0.000000+0.857786j  0.000000+4.130941j  0.000000+7.706829j   \n",
            "0  0.000000+0.857786j  0.000000+4.130941j  0.000000+7.706829j   \n",
            "\n",
            "               v252                v253                v254  \\\n",
            "0  0.00000+8.80311j  0.000000+9.289067j -0.000000-0.363868j   \n",
            "0  0.00000+8.80311j  0.000000+9.289067j -0.000000-0.363868j   \n",
            "0  0.00000+8.80311j  0.000000+9.289067j -0.000000-0.363868j   \n",
            "0  0.00000+8.80311j  0.000000+9.289067j -0.000000-0.363868j   \n",
            "\n",
            "                 v255                  rk  \n",
            "0  0.000000+1.689227j -0.000000-0.872574j  \n",
            "0  0.000000+1.689227j -0.000000-0.872602j  \n",
            "0  0.000000+1.689227j -0.000000-0.872483j  \n",
            "0  0.000000+1.689227j -0.000000-0.872500j  \n",
            "\n",
            "[4 rows x 513 columns]\n"
          ]
        }
      ],
      "source": [
        "gk = generate_gk()\n",
        "v = generate_v()\n",
        "rk = generate_rk()\n",
        "# print(gk)\n",
        "# print(v)\n",
        "# print(rk)\n",
        "\n",
        "user_power = np.power(10,-2.35)    # 24\n",
        "# print(theta_0)\n",
        "# print(len(rk[0]))\n",
        "# print(len(theta_0))\n",
        "# print(len(gk))\n",
        "# df_u1 = pd.DataFrame(list(zip(gk, v, rk, theta_0)), columns=['gk', 'v', 'rk', 'theta_0'])\n",
        "\n",
        "X = pd.DataFrame()\n",
        "for user in range(num_users):\n",
        "    dic = {}\n",
        "    for i in range(len(gk[user])):\n",
        "        dic['gk'+str(i)] = gk[user][i]\n",
        "    for i in range(len(v)):\n",
        "        dic['v'+str(i)] = v[i]\n",
        "    dic['rk'] = rk[user]\n",
        "    x = pd.DataFrame.from_dict(dic)\n",
        "\n",
        "    X = pd.concat([X,x])\n",
        "\n",
        "y = pd.DataFrame()\n",
        "for user in range(num_users):\n",
        "    theta_matrix = generate_theta()\n",
        "    theta = [theta_matrix[i][i] for i in range(len(theta_matrix))]\n",
        "    y_dic = {}\n",
        "    for i in range(len(theta)):\n",
        "        y_dic['theta'+str(i)] = [theta[i]]\n",
        "    y_dic['pk'] = [user_power]\n",
        "    # print(y_dic)\n",
        "    y_df = pd.DataFrame.from_dict(y_dic)\n",
        "\n",
        "    y = pd.concat([y, y_df])\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "print(X.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.model = keras.models.Sequential()\n",
        "        self.gk = X[[col for col in X if col.startswith('gk')]].to_numpy()\n",
        "        self.v = X[[col for col in X if col.startswith('v')]].to_numpy()\n",
        "        self.rk = X[[col for col in X if col.startswith('rk')]].to_numpy()\n",
        "\n",
        "    def loss_func(self, y_true, y_pred):\n",
        "        hk_final = 0\n",
        "        for user in range(num_users):\n",
        "            theta_1 = tf.linalg.diag(y_pred[:,:M][user])\n",
        "            # pk = y_pred[:,-1]\n",
        "            # pk_ = pk[0]\n",
        "            # print(pk_)\n",
        "            v_ = tf.transpose(tf.convert_to_tensor(self.v[user], dtype=tf.complex128))\n",
        "            # print(v_)\n",
        "            a = tf.math.conj(tf.convert_to_tensor(self.gk[user]))\n",
        "            # print(a)\n",
        "            theta_1= tf.cast(theta_1, tf.complex128)\n",
        "            b = tf.tensordot(theta_1, v_, axes=1)\n",
        "            b_ = tf.convert_to_tensor(b)\n",
        "            # print(b_)\n",
        "            rk_ = tf.convert_to_tensor(self.rk[user], dtype=tf.complex128)\n",
        "            # print(rk_)\n",
        "            c = tf.tensordot(a, b_, axes=1)\n",
        "            c_ = tf.convert_to_tensor(c)\n",
        "            # print(c_)\n",
        "            hk = (tf.linalg.norm(rk_ + c_))**2\n",
        "            # print(hk)\n",
        "            hk_ = tf.fill((1,), hk)\n",
        "            # print(hk_)\n",
        "            hk_final = hk_final + hk_\n",
        "            # print(hk_)\n",
        "        return -hk_final\n",
        "        # RkO = 1/4*(np.log2( 1+ ((pk[0] * hk) * 4)/sigma**2 )) #4 -> users\n",
        "        # rate = (pk*hk)\n",
        "    # def loss_func(self, y_true, y_pred):\n",
        "    #     tf.print(y_pred)\n",
        "    #     squared_difference = tf.square(y_true - y_pred)\n",
        "    #     return tf.reduce_mean(squared_difference, axis=-1)\n",
        "\n",
        "    def InputLayer(self, Input):\n",
        "        self.model.add(keras.layers.Flatten(input_shape=Input))\n",
        "    def AddLayers(self, n_layers, neurons, activation):\n",
        "        for i in range(n_layers):\n",
        "            self.model.add(keras.layers.BatchNormalization())\n",
        "            self.model.add(keras.layers.Dense(neurons[i], activation=activation[i],kernel_initializer='he_normal'))\n",
        "            # self.model.add(keras.layers.Dropout(0.2))\n",
        "            # print(self.model.summary())\n",
        "    def fit(self,loss, X_train, y_train):\n",
        "        # self.loss_func(X_train, y_train)\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=0.009)\n",
        "        self.model.compile(loss=self.loss_func, optimizer=optimizer, run_eagerly=True)\n",
        "        history = self.model.fit(X_train, y_train, epochs=250)\n",
        "        # print(type(self.model))\n",
        "        return history\n",
        "    \n",
        "    def predict(self, X):\n",
        "        y = self.model.predict(X)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1/1 [==============================] - 0s 43ms/step - loss: -201458.7969\n",
            "Epoch 2/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -709436.7500\n",
            "Epoch 3/250\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -869621.5000\n",
            "Epoch 4/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -1799033.5000\n",
            "Epoch 5/250\n",
            "1/1 [==============================] - 0s 42ms/step - loss: -3853073.5000\n",
            "Epoch 6/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -5445556.5000\n",
            "Epoch 7/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -3562007.0000\n",
            "Epoch 8/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -4977744.5000\n",
            "Epoch 9/250\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -6244699.5000\n",
            "Epoch 10/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -9189569.0000\n",
            "Epoch 11/250\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -12871270.0000\n",
            "Epoch 12/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -6558475.5000\n",
            "Epoch 13/250\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -12257581.0000\n",
            "Epoch 14/250\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17137474.0000\n",
            "Epoch 15/250\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -19341978.0000\n",
            "Epoch 16/250\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -10710313.0000\n",
            "Epoch 17/250\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -12734094.0000\n",
            "Epoch 18/250\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -26761392.0000\n",
            "Epoch 19/250\n",
            "1/1 [==============================] - 0s 43ms/step - loss: -14847603.0000\n",
            "Epoch 20/250\n",
            "1/1 [==============================] - 0s 43ms/step - loss: -20757762.0000\n",
            "Epoch 21/250\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -20306022.0000\n",
            "Epoch 22/250\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -17431648.0000\n",
            "Epoch 23/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -21176196.0000\n",
            "Epoch 24/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -34668372.0000\n",
            "Epoch 25/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -26018220.0000\n",
            "Epoch 26/250\n",
            "1/1 [==============================] - 0s 42ms/step - loss: -30391572.0000\n",
            "Epoch 27/250\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -23575978.0000\n",
            "Epoch 28/250\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -27564966.0000\n",
            "Epoch 29/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -29187552.0000\n",
            "Epoch 30/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -33725072.0000\n",
            "Epoch 31/250\n",
            "1/1 [==============================] - 0s 43ms/step - loss: -28205920.0000\n",
            "Epoch 32/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -38883548.0000\n",
            "Epoch 33/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -27909906.0000\n",
            "Epoch 34/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -31497608.0000\n",
            "Epoch 35/250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -37392888.0000\n",
            "Epoch 36/250\n",
            "1/1 [==============================] - 0s 42ms/step - loss: -30855092.0000\n",
            "Epoch 37/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -33955972.0000\n",
            "Epoch 38/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -32574676.0000\n",
            "Epoch 39/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -36691952.0000\n",
            "Epoch 40/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -37189384.0000\n",
            "Epoch 41/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -34861508.0000\n",
            "Epoch 42/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -36631724.0000\n",
            "Epoch 43/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -36616736.0000\n",
            "Epoch 44/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -33592896.0000\n",
            "Epoch 45/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -37403652.0000\n",
            "Epoch 46/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -36731428.0000\n",
            "Epoch 47/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -40033752.0000\n",
            "Epoch 48/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -38234896.0000\n",
            "Epoch 49/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -37422124.0000\n",
            "Epoch 50/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -37299532.0000\n",
            "Epoch 51/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -36611480.0000\n",
            "Epoch 52/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -38533980.0000\n",
            "Epoch 53/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -38656124.0000\n",
            "Epoch 54/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -38224456.0000\n",
            "Epoch 55/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -37245636.0000\n",
            "Epoch 56/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -35269112.0000\n",
            "Epoch 57/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -37450716.0000\n",
            "Epoch 58/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40111580.0000\n",
            "Epoch 59/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -38048136.0000\n",
            "Epoch 60/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40914620.0000\n",
            "Epoch 61/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -38692540.0000\n",
            "Epoch 62/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40969308.0000\n",
            "Epoch 63/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -40396060.0000\n",
            "Epoch 64/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -35830144.0000\n",
            "Epoch 65/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -39018172.0000\n",
            "Epoch 66/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -36857036.0000\n",
            "Epoch 67/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41586964.0000\n",
            "Epoch 68/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -39270028.0000\n",
            "Epoch 69/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39897832.0000\n",
            "Epoch 70/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -37453772.0000\n",
            "Epoch 71/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -39055144.0000\n",
            "Epoch 72/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -36326744.0000\n",
            "Epoch 73/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -37526812.0000\n",
            "Epoch 74/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39365420.0000\n",
            "Epoch 75/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -40332000.0000\n",
            "Epoch 76/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40189728.0000\n",
            "Epoch 77/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -36499752.0000\n",
            "Epoch 78/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -38600544.0000\n",
            "Epoch 79/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -41255608.0000\n",
            "Epoch 80/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41617948.0000\n",
            "Epoch 81/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -39129604.0000\n",
            "Epoch 82/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -40314656.0000\n",
            "Epoch 83/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -38137800.0000\n",
            "Epoch 84/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -37803700.0000\n",
            "Epoch 85/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -38455172.0000\n",
            "Epoch 86/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -36733568.0000\n",
            "Epoch 87/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41000972.0000\n",
            "Epoch 88/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -42013320.0000\n",
            "Epoch 89/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -39122840.0000\n",
            "Epoch 90/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -37115420.0000\n",
            "Epoch 91/250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -37173672.0000\n",
            "Epoch 92/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40919164.0000\n",
            "Epoch 93/250\n",
            "1/1 [==============================] - 0s 42ms/step - loss: -41140036.0000\n",
            "Epoch 94/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -41193500.0000\n",
            "Epoch 95/250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -39224336.0000\n",
            "Epoch 96/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -40188288.0000\n",
            "Epoch 97/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39666188.0000\n",
            "Epoch 98/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -37268096.0000\n",
            "Epoch 99/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -37456480.0000\n",
            "Epoch 100/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -38462876.0000\n",
            "Epoch 101/250\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -38658252.0000\n",
            "Epoch 102/250\n",
            "1/1 [==============================] - 0s 42ms/step - loss: -41702840.0000\n",
            "Epoch 103/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41819788.0000\n",
            "Epoch 104/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -39786500.0000\n",
            "Epoch 105/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -41406800.0000\n",
            "Epoch 106/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -38470208.0000\n",
            "Epoch 107/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -38145300.0000\n",
            "Epoch 108/250\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -42254004.0000\n",
            "Epoch 109/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -38753488.0000\n",
            "Epoch 110/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -41390464.0000\n",
            "Epoch 111/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -39429068.0000\n",
            "Epoch 112/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -38597452.0000\n",
            "Epoch 113/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40516984.0000\n",
            "Epoch 114/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -40855112.0000\n",
            "Epoch 115/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -38205840.0000\n",
            "Epoch 116/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40673432.0000\n",
            "Epoch 117/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -39420136.0000\n",
            "Epoch 118/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -42388816.0000\n",
            "Epoch 119/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -39265344.0000\n",
            "Epoch 120/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39420668.0000\n",
            "Epoch 121/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40544528.0000\n",
            "Epoch 122/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -41876912.0000\n",
            "Epoch 123/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -38120856.0000\n",
            "Epoch 124/250\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -38820304.0000\n",
            "Epoch 125/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -40894228.0000\n",
            "Epoch 126/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39239312.0000\n",
            "Epoch 127/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -38071796.0000\n",
            "Epoch 128/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -40722572.0000\n",
            "Epoch 129/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39355844.0000\n",
            "Epoch 130/250\n",
            "1/1 [==============================] - 0s 42ms/step - loss: -38290292.0000\n",
            "Epoch 131/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -36360300.0000\n",
            "Epoch 132/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -37663792.0000\n",
            "Epoch 133/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -40798336.0000\n",
            "Epoch 134/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -37710532.0000\n",
            "Epoch 135/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -40020988.0000\n",
            "Epoch 136/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -39232776.0000\n",
            "Epoch 137/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -39174380.0000\n",
            "Epoch 138/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40950088.0000\n",
            "Epoch 139/250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -36903596.0000\n",
            "Epoch 140/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -38496472.0000\n",
            "Epoch 141/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -36921172.0000\n",
            "Epoch 142/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40840856.0000\n",
            "Epoch 143/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39469372.0000\n",
            "Epoch 144/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -42240312.0000\n",
            "Epoch 145/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -39081888.0000\n",
            "Epoch 146/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -36637960.0000\n",
            "Epoch 147/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39762236.0000\n",
            "Epoch 148/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40599944.0000\n",
            "Epoch 149/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -38403176.0000\n",
            "Epoch 150/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -36741448.0000\n",
            "Epoch 151/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41138176.0000\n",
            "Epoch 152/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -41159204.0000\n",
            "Epoch 153/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39914688.0000\n",
            "Epoch 154/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39340044.0000\n",
            "Epoch 155/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41202644.0000\n",
            "Epoch 156/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -36894160.0000\n",
            "Epoch 157/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -36921968.0000\n",
            "Epoch 158/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41011968.0000\n",
            "Epoch 159/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40080400.0000\n",
            "Epoch 160/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -38911332.0000\n",
            "Epoch 161/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -41421748.0000\n",
            "Epoch 162/250\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -41033004.0000\n",
            "Epoch 163/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -39083656.0000\n",
            "Epoch 164/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -38054536.0000\n",
            "Epoch 165/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -42230440.0000\n",
            "Epoch 166/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -37761452.0000\n",
            "Epoch 167/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -40596052.0000\n",
            "Epoch 168/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -37468880.0000\n",
            "Epoch 169/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -40645004.0000\n",
            "Epoch 170/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39228864.0000\n",
            "Epoch 171/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -39243124.0000\n",
            "Epoch 172/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -40075396.0000\n",
            "Epoch 173/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -37981088.0000\n",
            "Epoch 174/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41851344.0000\n",
            "Epoch 175/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -40098812.0000\n",
            "Epoch 176/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -38079128.0000\n",
            "Epoch 177/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40136768.0000\n",
            "Epoch 178/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -38951120.0000\n",
            "Epoch 179/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -39092880.0000\n",
            "Epoch 180/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -38272848.0000\n",
            "Epoch 181/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -41441972.0000\n",
            "Epoch 182/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -40442956.0000\n",
            "Epoch 183/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -41691132.0000\n",
            "Epoch 184/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -40430800.0000\n",
            "Epoch 185/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -40580044.0000\n",
            "Epoch 186/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -39296008.0000\n",
            "Epoch 187/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39184244.0000\n",
            "Epoch 188/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -41797484.0000\n",
            "Epoch 189/250\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -41492516.0000\n",
            "Epoch 190/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -38345652.0000\n",
            "Epoch 191/250\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -41490412.0000\n",
            "Epoch 192/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -38084300.0000\n",
            "Epoch 193/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39086188.0000\n",
            "Epoch 194/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -39212036.0000\n",
            "Epoch 195/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -39253012.0000\n",
            "Epoch 196/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -39245232.0000\n",
            "Epoch 197/250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -40420384.0000\n",
            "Epoch 198/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -37393472.0000\n",
            "Epoch 199/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -39055896.0000\n",
            "Epoch 200/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40508048.0000\n",
            "Epoch 201/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -37454140.0000\n",
            "Epoch 202/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -40368972.0000\n",
            "Epoch 203/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -39054256.0000\n",
            "Epoch 204/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -40531604.0000\n",
            "Epoch 205/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -41691000.0000\n",
            "Epoch 206/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -40358092.0000\n",
            "Epoch 207/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -37507344.0000\n",
            "Epoch 208/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -39054280.0000\n",
            "Epoch 209/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40569952.0000\n",
            "Epoch 210/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -38037276.0000\n",
            "Epoch 211/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -41586408.0000\n",
            "Epoch 212/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -38555848.0000\n",
            "Epoch 213/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -37515748.0000\n",
            "Epoch 214/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -40522368.0000\n",
            "Epoch 215/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39064284.0000\n",
            "Epoch 216/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -38502492.0000\n",
            "Epoch 217/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39027676.0000\n",
            "Epoch 218/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -39444496.0000\n",
            "Epoch 219/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -40591340.0000\n",
            "Epoch 220/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -41548984.0000\n",
            "Epoch 221/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -40342032.0000\n",
            "Epoch 222/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -39757728.0000\n",
            "Epoch 223/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -38539576.0000\n",
            "Epoch 224/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40321960.0000\n",
            "Epoch 225/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -40341108.0000\n",
            "Epoch 226/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -39169436.0000\n",
            "Epoch 227/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -39468316.0000\n",
            "Epoch 228/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -39058044.0000\n",
            "Epoch 229/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -40416692.0000\n",
            "Epoch 230/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -38042332.0000\n",
            "Epoch 231/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39065848.0000\n",
            "Epoch 232/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -40561724.0000\n",
            "Epoch 233/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -39089404.0000\n",
            "Epoch 234/250\n",
            "1/1 [==============================] - 0s 42ms/step - loss: -40340484.0000\n",
            "Epoch 235/250\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -39460284.0000\n",
            "Epoch 236/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -39740056.0000\n",
            "Epoch 237/250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -38574792.0000\n",
            "Epoch 238/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -41493800.0000\n",
            "Epoch 239/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -41652908.0000\n",
            "Epoch 240/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -40419812.0000\n",
            "Epoch 241/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -40427864.0000\n",
            "Epoch 242/250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -40418620.0000\n",
            "Epoch 243/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40420260.0000\n",
            "Epoch 244/250\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -40574492.0000\n",
            "Epoch 245/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -40574744.0000\n",
            "Epoch 246/250\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -38046236.0000\n",
            "Epoch 247/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -41684444.0000\n",
            "Epoch 248/250\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -39163644.0000\n",
            "Epoch 249/250\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -39457460.0000\n",
            "Epoch 250/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -39075448.0000\n",
            "power allocation =  -0.032616604\n",
            "theta[n] =  [-0.9999975   0.9997642   0.9999897   0.999911   -0.9983352  -0.9999752\n",
            "  0.9999434  -0.99998754  0.9999997  -0.99999213  0.9996117  -0.9999618\n",
            " -0.98833835  0.99996877  0.9999707   0.99992716  0.9949531  -0.99996406\n",
            " -0.99995553  0.99994546 -0.9999778  -0.9999979  -0.9998074  -0.99982524\n",
            "  0.99995416  0.99459773  0.9999479  -0.99997616 -0.99579376  0.9989429\n",
            "  0.9999916  -0.99997795  0.9999905   0.99998045  0.9999856  -0.9999777\n",
            " -0.99999785 -0.99996024 -0.99999344  0.9994483   0.99915236 -0.99999905\n",
            "  0.9739837   0.9999978  -0.9995466   0.9999224   0.99985427 -0.9999526\n",
            " -0.99998385 -0.99998915  0.9999984   0.99998784  0.99928135  0.99998045\n",
            "  0.99998546 -0.9999765   0.99994093 -0.99998224 -0.99999595 -0.99993545\n",
            "  0.9998495   0.9998073   0.99999493 -0.99910426 -0.9934367   0.99997026\n",
            " -0.99905246 -0.9999174  -0.985589    0.9999871   0.99996275  0.9999977\n",
            " -0.9998933   0.9999895  -0.99998605 -0.9999979   0.99856836 -0.9990555\n",
            "  0.99998754  0.99999905 -0.99997884  0.99998504  0.9999857  -0.99991107\n",
            " -0.97896403  0.9999347  -0.9999989  -0.9999802   0.9999362  -0.99997157\n",
            "  0.9999907   0.999933   -0.99998814 -0.9999968  -0.99991584 -0.99992883\n",
            " -0.9999896  -0.99998826  0.9998237  -0.9996852   0.99999565  0.9999472\n",
            " -0.99930173 -0.9998633  -0.99999136 -0.99969643  0.9999961  -0.99996525\n",
            " -0.99547225  0.9998818   0.99999577 -0.9999096   0.9999912  -0.99988127\n",
            " -0.99993473  0.9989785  -0.99999416  0.9999925   0.99998546  0.9999907\n",
            "  0.99964917 -0.99998945  0.99990696  0.9999871   0.99134606 -0.99994826\n",
            "  0.9999052   0.99993277  0.99979705  0.9999738   0.9998391  -0.9999893\n",
            "  0.99999905 -0.9999818  -0.99997056  0.99998355 -0.9995182   0.9999784\n",
            "  0.999977   -0.99999505  0.9999972  -0.9999822  -0.999901   -0.9999858\n",
            "  0.9999952  -0.99980545 -0.99999493 -0.9996069   0.9995404   0.9999947\n",
            "  0.9999049  -0.9998534  -0.9999249   0.999968    0.9999145  -0.9999528\n",
            " -0.9999961   0.99993455  0.99997026  0.998659   -0.9999988   0.99512094\n",
            " -0.9999539  -0.9999865   0.9999815   0.9999859  -0.99998176  0.9999603\n",
            "  0.9999917  -0.999964   -0.9999982  -0.9999777  -0.99309516  0.9999899\n",
            " -0.99998206  0.9999545   0.99999404  0.9999851   0.99989665 -0.99888504\n",
            " -0.99999523  0.9995467  -0.9999997  -0.9998753   0.99995524  0.9999821\n",
            "  0.9999979   0.9999895   0.9999741   0.99995863  0.99969536  0.99418956\n",
            " -0.99997574 -0.99997205 -0.9959471  -0.89954513  0.99954665 -0.99995166\n",
            "  0.9999943   0.9990948  -0.9999123   0.99920315  0.9999603   0.99999154\n",
            "  0.9999751  -0.999803    1.         -0.99998355 -0.9999617  -0.9999781\n",
            " -0.99999696  0.9995923   0.9999996   0.9999759   0.99997956 -0.98513126\n",
            " -0.9999256  -0.99999917 -0.99999833 -0.9999966   0.999986   -0.99994105\n",
            "  0.99990904 -0.9999491  -0.99986047  0.99995834  0.99884915 -0.99997514\n",
            " -0.99976486 -0.9984304  -0.9999621   0.99998224  0.9999078  -0.9999429\n",
            "  0.9999445   0.9999747   0.99995095 -0.9999988   0.9999742   0.99583286\n",
            "  0.9996252  -0.99998844  0.9999786  -0.99964434  0.99992305 -0.9999878\n",
            " -0.9996196   0.9999819   0.9999309  -0.99995613  0.99991107  0.99993867\n",
            "  0.99995077  0.99999416  0.9999602  -0.9999978 ]\n"
          ]
        }
      ],
      "source": [
        "nmodel = NeuralNetwork()\n",
        "nmodel.InputLayer([X.shape[1]])\n",
        "nmodel.AddLayers(2,[30,y.shape[1]], [\"relu\",\"tanh\"])\n",
        "model = nmodel.fit(\"mse\", X,y)\n",
        "ypred = nmodel.predict(X)\n",
        "print(\"power allocation = \",ypred[0][M])\n",
        "print(\"theta[n] = \", ypred[0][:M])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': [-201458.796875, -709436.75, -869621.5, -1799033.5, -3853073.5, -5445556.5, -3562007.0, -4977744.5, -6244699.5, -9189569.0, -12871270.0, -6558475.5, -12257581.0, -17137474.0, -19341978.0, -10710313.0, -12734094.0, -26761392.0, -14847603.0, -20757762.0, -20306022.0, -17431648.0, -21176196.0, -34668372.0, -26018220.0, -30391572.0, -23575978.0, -27564966.0, -29187552.0, -33725072.0, -28205920.0, -38883548.0, -27909906.0, -31497608.0, -37392888.0, -30855092.0, -33955972.0, -32574676.0, -36691952.0, -37189384.0, -34861508.0, -36631724.0, -36616736.0, -33592896.0, -37403652.0, -36731428.0, -40033752.0, -38234896.0, -37422124.0, -37299532.0, -36611480.0, -38533980.0, -38656124.0, -38224456.0, -37245636.0, -35269112.0, -37450716.0, -40111580.0, -38048136.0, -40914620.0, -38692540.0, -40969308.0, -40396060.0, -35830144.0, -39018172.0, -36857036.0, -41586964.0, -39270028.0, -39897832.0, -37453772.0, -39055144.0, -36326744.0, -37526812.0, -39365420.0, -40332000.0, -40189728.0, -36499752.0, -38600544.0, -41255608.0, -41617948.0, -39129604.0, -40314656.0, -38137800.0, -37803700.0, -38455172.0, -36733568.0, -41000972.0, -42013320.0, -39122840.0, -37115420.0, -37173672.0, -40919164.0, -41140036.0, -41193500.0, -39224336.0, -40188288.0, -39666188.0, -37268096.0, -37456480.0, -38462876.0, -38658252.0, -41702840.0, -41819788.0, -39786500.0, -41406800.0, -38470208.0, -38145300.0, -42254004.0, -38753488.0, -41390464.0, -39429068.0, -38597452.0, -40516984.0, -40855112.0, -38205840.0, -40673432.0, -39420136.0, -42388816.0, -39265344.0, -39420668.0, -40544528.0, -41876912.0, -38120856.0, -38820304.0, -40894228.0, -39239312.0, -38071796.0, -40722572.0, -39355844.0, -38290292.0, -36360300.0, -37663792.0, -40798336.0, -37710532.0, -40020988.0, -39232776.0, -39174380.0, -40950088.0, -36903596.0, -38496472.0, -36921172.0, -40840856.0, -39469372.0, -42240312.0, -39081888.0, -36637960.0, -39762236.0, -40599944.0, -38403176.0, -36741448.0, -41138176.0, -41159204.0, -39914688.0, -39340044.0, -41202644.0, -36894160.0, -36921968.0, -41011968.0, -40080400.0, -38911332.0, -41421748.0, -41033004.0, -39083656.0, -38054536.0, -42230440.0, -37761452.0, -40596052.0, -37468880.0, -40645004.0, -39228864.0, -39243124.0, -40075396.0, -37981088.0, -41851344.0, -40098812.0, -38079128.0, -40136768.0, -38951120.0, -39092880.0, -38272848.0, -41441972.0, -40442956.0, -41691132.0, -40430800.0, -40580044.0, -39296008.0, -39184244.0, -41797484.0, -41492516.0, -38345652.0, -41490412.0, -38084300.0, -39086188.0, -39212036.0, -39253012.0, -39245232.0, -40420384.0, -37393472.0, -39055896.0, -40508048.0, -37454140.0, -40368972.0, -39054256.0, -40531604.0, -41691000.0, -40358092.0, -37507344.0, -39054280.0, -40569952.0, -38037276.0, -41586408.0, -38555848.0, -37515748.0, -40522368.0, -39064284.0, -38502492.0, -39027676.0, -39444496.0, -40591340.0, -41548984.0, -40342032.0, -39757728.0, -38539576.0, -40321960.0, -40341108.0, -39169436.0, -39468316.0, -39058044.0, -40416692.0, -38042332.0, -39065848.0, -40561724.0, -39089404.0, -40340484.0, -39460284.0, -39740056.0, -38574792.0, -41493800.0, -41652908.0, -40419812.0, -40427864.0, -40418620.0, -40420260.0, -40574492.0, -40574744.0, -38046236.0, -41684444.0, -39163644.0, -39457460.0, -39075448.0]}\n"
          ]
        }
      ],
      "source": [
        "print((model.history))\n",
        "throughput = [-x for x in model.history['loss']]\n",
        "throughput1 = []\n",
        "y = []\n",
        "i = 0\n",
        "for x in throughput:\n",
        "    if i % 25 == 0:\n",
        "        throughput1.append(x)\n",
        "    i+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(throughput,marker = \".\")\n",
        "# plt.plot(model.history['val_loss'])\n",
        "plt.title('model throughput')\n",
        "plt.ylabel('throughput')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
